{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09d41974",
   "metadata": {},
   "source": [
    "2.Create representation of document by calculating term frequency and inverse document frequency ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e215ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    " #import the necessary libraries \n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a541a277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'', 'an', 'of', 'think', 'scientist', 'learning', 'data', 'and', 'intelligance', 'more', 'technology', 'artificial', 'has', 'intelligence', 'job', 'sexiest', 'part', 'the', 'to', 'A', 'promising', 'emerging', '21st', 'than', 'Data', 'for', 'century', 'machine', 'is', 'Science', 'code', 'key', 'science'}\n"
     ]
    }
   ],
   "source": [
    "first_sentence = \"Data Science is the sexiest job of the 21st century\"\n",
    "second_sentence = \"machine learning is the key for data science\"\n",
    "third_sentence = \"machine learning is part of artificial intelligence\"\n",
    "fourth_sentence= \"A data scientist has to think more than code \"\n",
    "fifth_sentence = \"artificial intelligance is an emerging and promising technology\"\n",
    "#split the sentences so that  each word have their own string\n",
    "first_sentence = first_sentence.split(\" \")\n",
    "second_sentence = second_sentence.split(\" \")\n",
    "third_sentence = third_sentence.split(\" \")\n",
    "fourth_sentence = fourth_sentence.split(\" \")\n",
    "fifth_sentence = fifth_sentence.split(\" \")\n",
    "#join them to remove common duplicate words\n",
    "total= set(first_sentence).union(set(second_sentence).union(third_sentence).union(fourth_sentence).union(fifth_sentence))\n",
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16215735",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictA = dict.fromkeys(total, 0) \n",
    "wordDictB = dict.fromkeys(total, 0)\n",
    "wordDictC = dict.fromkeys(total, 0)\n",
    "wordDictD = dict.fromkeys(total, 0)\n",
    "wordDictE = dict.fromkeys(total, 0)\n",
    "for word in first_sentence:\n",
    "    wordDictA[word]+=1\n",
    "    \n",
    "for word in second_sentence:\n",
    "    wordDictB[word]+=1\n",
    "    \n",
    "for word in third_sentence:\n",
    "    wordDictC[word]+=1\n",
    "\n",
    "for word in fourth_sentence:\n",
    "    wordDictD[word]+=1\n",
    "    \n",
    "for word in fifth_sentence:\n",
    "    wordDictE[word]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "901fb25e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>an</th>\n",
       "      <th>of</th>\n",
       "      <th>think</th>\n",
       "      <th>scientist</th>\n",
       "      <th>learning</th>\n",
       "      <th>data</th>\n",
       "      <th>and</th>\n",
       "      <th>intelligance</th>\n",
       "      <th>more</th>\n",
       "      <th>...</th>\n",
       "      <th>than</th>\n",
       "      <th>Data</th>\n",
       "      <th>for</th>\n",
       "      <th>century</th>\n",
       "      <th>machine</th>\n",
       "      <th>is</th>\n",
       "      <th>Science</th>\n",
       "      <th>code</th>\n",
       "      <th>key</th>\n",
       "      <th>science</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      an  of  think  scientist  learning  data  and  intelligance  more  ...  \\\n",
       "0  0   0   1      0          0         0     0    0             0     0  ...   \n",
       "1  0   0   0      0          0         1     1    0             0     0  ...   \n",
       "2  0   0   1      0          0         1     0    0             0     0  ...   \n",
       "3  1   0   0      1          1         0     1    0             0     1  ...   \n",
       "4  0   1   0      0          0         0     0    1             1     0  ...   \n",
       "\n",
       "   than  Data  for  century  machine  is  Science  code  key  science  \n",
       "0     0     1    0        1        0   1        1     0    0        0  \n",
       "1     0     0    1        0        1   1        0     0    1        1  \n",
       "2     0     0    0        0        1   1        0     0    0        0  \n",
       "3     1     0    0        0        0   0        0     1    0        0  \n",
       "4     0     0    0        0        0   1        0     0    0        0  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now we put them in a dataframe and then view the result\n",
    "pd.DataFrame([wordDictA, wordDictB, wordDictC, wordDictD, wordDictE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3f3d80",
   "metadata": {},
   "source": [
    "# Term Frequency:\n",
    "the number of times a term occurs in a document.The number of times a word appears in a document divded by the total number of words in the document\n",
    " it can be calculated by tf(t,d) = count of t in d / number of words in d\n",
    " here t is term and d is document .\n",
    " \n",
    " Assume that a document has 20 words and 5 of them is the word “great”. The TF will be calculated as:\n",
    "tf: 5/20 = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c77dcfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTF(wordDict, doc):\n",
    "    tfDict = {}\n",
    "    corpusCount = len(doc)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/float(corpusCount)\n",
    "    return(tfDict)\n",
    "#running our sentences through the tf function:\n",
    "tfFirst = computeTF(wordDictA, first_sentence)\n",
    "tfSecond = computeTF(wordDictB, second_sentence)\n",
    "tfThird = computeTF(wordDictC, third_sentence)\n",
    "tfFourth = computeTF(wordDictD, fourth_sentence)\n",
    "tfFifth = computeTF(wordDictE, fifth_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1248164",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           an        of  think  scientist  learning   data    and  \\\n",
      "0  0.0  0.000  0.100000    0.0        0.0  0.000000  0.000  0.000   \n",
      "1  0.0  0.000  0.000000    0.0        0.0  0.125000  0.125  0.000   \n",
      "2  0.0  0.000  0.142857    0.0        0.0  0.142857  0.000  0.000   \n",
      "3  0.1  0.000  0.000000    0.1        0.1  0.000000  0.100  0.000   \n",
      "4  0.0  0.125  0.000000    0.0        0.0  0.000000  0.000  0.125   \n",
      "\n",
      "   intelligance  more  ...  than  Data    for  century   machine        is  \\\n",
      "0         0.000   0.0  ...   0.0   0.1  0.000      0.1  0.000000  0.100000   \n",
      "1         0.000   0.0  ...   0.0   0.0  0.125      0.0  0.125000  0.125000   \n",
      "2         0.000   0.0  ...   0.0   0.0  0.000      0.0  0.142857  0.142857   \n",
      "3         0.000   0.1  ...   0.1   0.0  0.000      0.0  0.000000  0.000000   \n",
      "4         0.125   0.0  ...   0.0   0.0  0.000      0.0  0.000000  0.125000   \n",
      "\n",
      "   Science  code    key  science  \n",
      "0      0.1   0.0  0.000    0.000  \n",
      "1      0.0   0.0  0.125    0.125  \n",
      "2      0.0   0.0  0.000    0.000  \n",
      "3      0.0   0.1  0.000    0.000  \n",
      "4      0.0   0.0  0.000    0.000  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "#Converting to dataframe for visualization\n",
    "tf =pd.DataFrame([tfFirst, tfSecond, tfThird,tfFourth, tfFifth])\n",
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9e05405",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', 'think', 'scientist', 'learning', 'data', 'intelligance', 'technology', 'artificial', 'intelligence', 'job', 'sexiest', 'part', 'A', 'promising', 'emerging', '21st', 'Data', 'century', 'machine', 'Science', 'code', 'key', 'science']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "filtered_sentence = [w for w in wordDictA if not w in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3774eaf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'wordDictA' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\RAKSHA~1\\AppData\\Local\\Temp/ipykernel_20580/1135201478.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0midfDict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#inputing our sentences in the log file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0midfs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomputeIDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwordDictA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordDictB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordDictC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordDictD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwordDictE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'wordDictA' is not defined"
     ]
    }
   ],
   "source": [
    "def computeIDF(docList):\n",
    "    idfDict = {}\n",
    "    N = len(docList)\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0)\n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / (float(val) + 1))\n",
    "        \n",
    "    return(idfDict)\n",
    "#inputing our sentences in the log file\n",
    "idfs = computeIDF([wordDictA, wordDictB, wordDictC, wordDictD, wordDictE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47d55895",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  and      Data   century       key     think  artificial  \\\n",
      "0  0.000000  0.000000  0.069897  0.069897  0.000000  0.000000    0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.087371  0.000000    0.000000   \n",
      "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000    0.099853   \n",
      "3  0.069897  0.000000  0.000000  0.000000  0.000000  0.069897    0.000000   \n",
      "4  0.000000  0.087371  0.000000  0.000000  0.000000  0.000000    0.087371   \n",
      "\n",
      "   learning       job      code  ...      21st  scientist      than  \\\n",
      "0  0.000000  0.069897  0.000000  ...  0.069897   0.000000  0.000000   \n",
      "1  0.087371  0.000000  0.000000  ...  0.000000   0.000000  0.000000   \n",
      "2  0.099853  0.000000  0.000000  ...  0.000000   0.000000  0.000000   \n",
      "3  0.000000  0.000000  0.069897  ...  0.000000   0.069897  0.069897   \n",
      "4  0.000000  0.000000  0.000000  ...  0.000000   0.000000  0.000000   \n",
      "\n",
      "   intelligence   machine      data   science   sexiest  intelligance  \\\n",
      "0      0.000000  0.000000  0.000000  0.000000  0.069897      0.000000   \n",
      "1      0.000000  0.087371  0.087371  0.087371  0.000000      0.000000   \n",
      "2      0.099853  0.099853  0.000000  0.000000  0.000000      0.000000   \n",
      "3      0.000000  0.000000  0.069897  0.000000  0.000000      0.000000   \n",
      "4      0.000000  0.000000  0.000000  0.000000  0.000000      0.087371   \n",
      "\n",
      "        for  \n",
      "0  0.000000  \n",
      "1  0.087371  \n",
      "2  0.000000  \n",
      "3  0.000000  \n",
      "4  0.000000  \n",
      "\n",
      "[5 rows x 33 columns]\n"
     ]
    }
   ],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return(tfidf)\n",
    "#running our two sentences through the IDF:\n",
    "idfFirst = computeTFIDF(tfFirst, idfs)\n",
    "idfSecond = computeTFIDF(tfSecond, idfs)\n",
    "idfThird = computeTFIDF(tfThird, idfs)\n",
    "idfFourth = computeTFIDF(tfFourth, idfs)\n",
    "idfFifth = computeTFIDF(tfFifth, idfs)\n",
    "#putting it in a dataframe\n",
    "idf= pd.DataFrame([idfFirst, idfSecond, idfThird, idfFourth, idfFifth])\n",
    "print(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d173e768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
